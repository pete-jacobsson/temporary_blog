{"title":"Not enough power for sensitivity: 14C Power and Sensitivity (weeks 4-5?)","markdown":{"yaml":{"title":"Not enough power for sensitivity: 14C Power and Sensitivity (weeks 4-5?)","author":"Pete","date":"2023-07-14","categories":["14C Power/Sensitivity","Research Design","Project Log"],"execute":{"message":false},"format":{"html":{"code-fold":true,"code-overflow":"scroll"}}},"headingText":"The models explored","containsRefs":false,"markdown":"\n\n```{r include=FALSE}\nlibrary(tidyverse)\nlibrary(broom)\n```\n\n\nHello everyone! Last time we left this project, we were on the verge of doing some exploratory modelling to start getting a more precise assessment of patterns we spotted during preliminary visualizations. To recap, we are trying to evaluate how much systematic offsets affect the precision of calibrated radiocarbon date ranges through simulating 10k of those models, with known offsets and checking how they vary. So far we spotted that model accuracy changes through time, as well as based on model precision (more accurate ones tend to get the answers wrong more often). We left off with two ways of approaching the exploratory modelling.\n\n-   One approach would treat uncertainty about the mean of the calibration curve as one of the model variables.\n-   The other approach would break up the data set based on target dates of the simulated radiocarbon dates, and build logistic models for each time period.\n\nThis installment focuses on the outcomes of the second approach. TLDR: if we want to push this any further, we need a lot more simulations than the 10k we've got.\n\n\nBefore going for our main goal, which is estimating how much offset is dangerous for these kinds of measurements during different time periods, we need to have a good model for describing how difference modelled date ranges relate to different combinations of underpinning factors.\n\nIn the current approach, I wanted to build seperate models for different points in time, which left me with two variables to consider: - Magnitude of systematic offset (ranging from -50 to 50 radiocarbon years - which are in reality a unit not of time, but of radiocarbon concentration) - Measurement precision (Between 8 and 32 radiocarbon years - less means more precise).\n\nWith these two variables four models were possible: 1. Offset only, ignoring any information from measurement precision 2. Precision only, ignoring offset magnitude 3. Both offset and precision 4. Offset, precision, and their interaction.\n\nWhile I was confident *a priori* that the second model was wrong (and I think you'll agree with me here), it was unclear how models 3 and 4 would compare, or for that matter whether model 1 might not be better on the grounds of parsimony (yes, measurement precision did seem to matter, but maybe not enough to justify it in model inclusion).\n\nI did spend some time two or three years ago chasing my own tail on that one time and time again. This time I decided to go for a simpler solution: I just applied all four models across the board, retaining the \"dubious\" model 2, as a baseline of bad model choice.\n\n## How the modelling was done\n\nThis plan involved a lot of models. To be specific four general model designs times however many bins times two to account for positive and negative offsets (after all, we cannot know if their impact on the data is symmetric in all cases and hence, I was reluctant to just use absolute values).\n\nI did the guts of the modelling with the [purr and broom method from R4DS](https://r4ds.had.co.nz/many-models.html): compressed the binned data using nest() and then applied the purpose built model functions to the relevant data. Hence the whole modelling process was over in a matter of maybe a half-hour (at least after I've cleared off the cobwebs on how the thing worked in the first place :stuck_out_tongue:).\n\n```{r, output = FALSE}\n\n\n### Set-up for fifty bins\nsingles_data_url <- \"https://raw.githubusercontent.com/pete-jacobsson/14C-power-sensitivity/main/simulation_results/singles_011_results.csv\" \nsingle_cals <- read_csv(url(singles_data_url))\n\n###Seperate pos from neg offsets and group things by cal curve \nsingle_cals_modelled <- single_cals %>%\n  mutate (\n    offset_pos = if_else(offset_magnitude > 0, TRUE, FALSE),\n    offset_magnitude = if_else(offset_pos, \n                               offset_magnitude, offset_magnitude * -1),\n    # Changing negs on offset magnitude to have a consistent direction at downstream visualization.\n    binned_targets = ntile(target_year, 50)\n  ) %>%\n  select(-target_year)\n\n### ntile() wouldn't return the relevant target years, so it needs to be done as its own thing.\nsingle_cals_modelled <- single_cals %>%\n  mutate(binned_targets = ntile(target_year, 50)) %>%\n  group_by(binned_targets) %>%\n  summarize( #Easy way to get years for the indiv bins, without too muchj headach\n    target_year = min(target_year)\n    ) %>%\n  inner_join(single_cals_modelled) %>% #Join the binned DF back in. No, I don't like this either!\n  group_by(offset_pos, target_year) %>%\n  nest()\n```\n\n```{r, output = FALSE}\n### Build the model functions\noffset_only_acc68 <- function(singles_data) {\n  glm(accuracy_68 ~ offset_magnitude, data = singles_data, \n      family = binomial)\n}\n\nsigma_only_acc68 <- function(singles_data) {\n  glm(accuracy_68 ~ measurement_error, data = singles_data, \n      family = binomial)\n}\n\noffset_sigma_acc68 <- function(singles_data) {\n  glm(accuracy_68 ~ measurement_error + offset_magnitude, data = singles_data, \n      family = binomial)\n}\n\noffset_sigma_interact_acc68 <- function(singles_data) {\n  glm(accuracy_68 ~ measurement_error + offset_magnitude + \n        measurement_error * offset_magnitude, \n      data = singles_data, family = binomial)\n}\n\n\noffset_only_acc95 <- function(singles_data) {\n  glm(accuracy_95 ~ offset_magnitude, data = singles_data, \n      family = binomial)\n}\n\nsigma_only_acc95 <- function(singles_data) {\n  glm(accuracy_95 ~ measurement_error, data = singles_data, \n      family = binomial)\n}\n\noffset_sigma_acc95 <- function(singles_data) {\n  glm(accuracy_95 ~ measurement_error + offset_magnitude, data = singles_data, \n      family = binomial)\n}\n\noffset_sigma_interact_acc95 <- function(singles_data) {\n  glm(accuracy_95 ~ measurement_error + offset_magnitude + \n        measurement_error * offset_magnitude, \n      data = singles_data, family = binomial)\n}\n\n## Note to future self: some smart pivoting earlier on could have simplified this by half :)\n\n```\n\n```{r, output = FALSE}\n### Model execution\nsingle_cals_modelled <- single_cals_modelled %>%\n  mutate(\n    offset_only_acc68 = map(data, offset_only_acc68),\n    sigma_only_acc68 = map(data, sigma_only_acc68),\n    offset_sigma_acc68 = map(data, offset_sigma_acc68),\n    offset_sigma_interact_acc68 = map(data, offset_sigma_interact_acc68),\n    offset_only_acc95 = map(data, offset_only_acc95),\n    sigma_only_acc95 = map(data, sigma_only_acc95),\n    offset_sigma_acc95 = map(data, offset_sigma_acc95),\n    offset_sigma_interact_acc95 = map(data, offset_sigma_interact_acc95)\n  )\n```\n\n\nNext, looked at model goodness params Then at model params themselves\n\nThen re-did the whole things with larger bins\n\n## Model fit quality\n\nUps and downs, big bit - 95.4% ranges\n\n## Model results discussion\n\nBase it off the research notes\n\nTwist - we lost the time dimension\n\n## Try again: bigger bins\n\n## Conclusion\n\nNot enough power for precision. Important bit - What changes in this characterization might be the baseline (intercept). This makes sense.\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"message":false,"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"output-file":"index.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.335","comments":{"giscus":{"repo":"pete-jacobsson/temporary_blog"}},"editor":"visual","theme":"simplex","sansfont":"Corbel","mainfont":"Cambria","title-block-banner":true,"title":"Not enough power for sensitivity: 14C Power and Sensitivity (weeks 4-5?)","author":"Pete","date":"2023-07-14","categories":["14C Power/Sensitivity","Research Design","Project Log"]},"extensions":{"book":{"multiFile":true}}}}}